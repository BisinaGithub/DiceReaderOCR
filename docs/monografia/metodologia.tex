\section{Metodologia }

Este capítulo descreve os métodos empregados no desenvolvimento do presente trabalho, 
com foco na estruturação do conjunto de dados, no processamento das imagens, no modelo de rede neural 
convolucional utilizado e nas estratégias de treinamento e validação do classificador. As decisões 
adotadas ao longo do processo são justificadas com base na realidade do projeto e nas limitações 
observadas durante a execução experimental.

\subsection{Coleta e Estruturação do Conjunto de Dados}
Para a realização dos testes, foi construído um conjunto de imagens próprio contendo fotografias de dados 
físicos utilizados em jogos de RPG. As imagens foram capturadas em estúdio fotográfico, com auxílio da
profissional Danielly Vitória Rodrigues, garantindo qualidade adequada de resolução, iluminação e enquadramento.

A figura~\ref{fig:image-counter} ilustra as quantidades de imagens coletadas para cada tipo de dado,
com um total de 1.124 imagens, distribuídas entre dados de 4, 6, e 8 e 10 lados.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{figuras/image-counter.png}
    \caption[Distribuição do conjunto da base de imagens]{
        \centering
        Distribuição do conjunto de imagens coletadas, com contagem por tipo de dado. \par
        \textit{Fonte: Autoria própria.}}
    \label{fig:image-counter}
\end{figure}

As imagens foram organizadas em pastas segundo os valores visíveis nas faces superiores dos dados, 
totalizando inicialmente 10 classes: \textit{0\_zero} até \textit{9\_nine}. Cada uma dessas pastas 
continha subpastas correspondentes aos diferentes tipos de dados (ex.: d4, d6, d8, d10)\,. 
Essa estrutura permitiu manter a diversidade de formatos dentro de cada valor, simulando 
condições reais de uso.

Entretanto, durante a análise da distribuição dos dados, foi observado que as classes 
\textit{0\_zero} até \textit{9\_nine} possuíam um número significativamente inferior de 
imagens em relação às demais. Essa escassez comprometia a representatividade estatística 
e a robustez do treinamento, além de aumentar o risco de viés ou sobreajuste da rede.

Por essa razão, optou-se por restringir o escopo do modelo inicial às classes 
\textbf{1 a 8}, que apresentavam uma quantidade razoável de imagens (acima de 80 
amostras por classe no total). As classes excluídas foram mantidas como 
possibilidade para expansão futura do projeto, mediante a ampliação da base.

\subsection{Processamento de Imagens}

Todas as imagens passaram por uma etapa de pré-processamento com o objetivo de remover 
espaços em branco ao redor dos dados e padronizar o formato das entradas. O processamento incluiu:

\begin{itemize}
\item \textbf{Corte absoluto}: Remoção de bordas fixas nas extremidades superior, inferior, 
esquerda e direita da imagem, mantendo foco no dado centralizado;
\item \textbf{Redimensionamento}: Ajuste da imagem para dimensões fixas de 160x160 pixels, 
facilitando a entrada na rede convolucional;
\item \textbf{Conversão RGB}: Padronização do canal de cor para compatibilidade com bibliotecas 
de visão computacional;
\end{itemize}

Esse tratamento foi realizado utilizando a biblioteca OpenCV. As imagens processadas foram salvas 
em pastas separadas para treino e validação.
\subsection{Divisão em Treinamento e Validação}

Para cada uma das classes (1 a 8)\,, as imagens foram embaralhadas e divididas em 80\% para 
treinamento e 20\% para validação. A divisão foi feita com semente fixa para garantir 
reprodutibilidade. Devido ao tamanho limitado do dataset, optou-se por não subdividir o 
conjunto de validação em um conjunto adicional de teste. Essa decisão visa manter uma 
quantidade mínima de imagens por classe nas avaliaçães, evitando séries com menos de cinco amostras.

Para futuros trabalhos, recomenda-se a coleta de um novo conjunto independente de imagens para 
testes finais e validação cruzada do modelo.

\subsection{Arquitetura da Rede Neural Convolucional}

A arquitetura da Rede Neural Convolucional (CNN) utilizada neste trabalho foi projetada para equilibrar 
capacidade de extração de características e simplicidade estrutural, considerando a dimensão relativamente 
pequena do conjunto de dados e o objetivo de classificação multiclasse (valores de 1 a 8). A estrutura final consiste em:

\begin{itemize}
\item Uma camada de reescalonamento (Rescaling) que normaliza os valores dos pixels das imagens de entrada para o intervalo
[0,1], dividindo por 255. Essa etapa é essencial para acelerar a convergência durante o treinamento.
\item Três blocos compostos por:
    \begin{itemize}
        \item Uma camada Conv2D com filtros 3x3, ativação \textbf{ReLU} e preenchimento 'same', com 16, 32 e 64 filtros, respectivamente; 
        \item Uma camada \textit{MaxPooling2D} após cada convolução, reduzindo as dimensões espaciais e promovendo generalização.
    \end{itemize}
\item Uma camada de \textit{Flatten}, que transforma o mapa de características extraído em um vetor unidimensional.
\item Uma camada densa \texttt{Dense}  com 128 neurônios e ativação \textbf{ReLU}, responsável por combinar as características extraídas.
\item Uma camada de saída \textit{Dense} com 8 neurônios e ativação \textbf{softmax}, adequada para classificação multiclasse com rótulos 
inteiros de 0 a 7 (associados às classes 1 a 8).
\end{itemize}

O modelo foi compilado com otimizador Adam e função de perda \textit{Sparse Categorical Crossentropy}, uma vez que os rótulos são 
inteiros e não codificados em one-hot, utilizando o otimizador Adam com taxa de aprendizado \textbf{0.0006}. A métrica de avaliação 
escolhida foi a acurácia.

A Figura~\ref{fig:modelo-cnn} apresenta um diagrama ilustrativo inspirado na arquitetura LeNet-5, 
um dos modelos de redes neurais convolucionais mais clássicos, proposto por LeCun et al. (1998) para 
reconhecimento de dígitos manuscritos. Embora a estrutura exata da rede implementada neste trabalho difira em 
termos de parâmetros, profundidade e dimensionalidade das entradas, o diagrama é representativo do fluxo de 
processamento típico de uma CNN: camadas de convolução seguidas por subamostragem (pooling), camadas densas 
totalmente conectadas e uma camada final com função de ativação \textit{softmax} para classificação multiclasse.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figuras/CNN-architecture.png}
    \caption[Esquema conceitual da arquitetura da Le-Net-5]{
        \centering
        Esquema conceitual da arquitetura de uma CNN, inspirado na LeNet-5. \par
        \textit{Fonte: Adaptado de LeCun et al. (1998)}.
        }
    \label{fig:modelo-cnn}
\end{figure}


\subsection{Treinamento do Modelo e Desafios Encontrados}

O treinamento da rede neural convolucional (CNN) foi conduzido de forma iterativa, passando por 
diversas fases de ajuste de parâmetros, avaliação de desempenho e análise qualitativa dos resultados. 
O objetivo principal era obter um modelo capaz de classificar corretamente os valores nas faces 
superiores de dados físicos de RPG com alta acurácia e boa generalização.

Inicialmente, o modelo foi treinado por 20 épocas, com um \textit{learning rate} de $0.001$, 
sem aplicação de técnicas de \textit{data augmentation}. Essa primeira configuração foi escolhida 
por simplicidade e por estar alinhada com abordagens comuns na literatura introdutória de CNNs.
Apesar da acurácia de treino apresentar crescimento constante, a acurácia de validação mostrava 
valores baixos, sugerindo dificuldade de generalização do modelo.

Tentativas subsequentes foram feitas para aumentar a robustez do treinamento por meio de técnicas 
de aumento de dados. Utilizou-se uma camada de \textit{data augmentation} composta por rotações, 
espelhamentos e zoom aleatórios. No entanto, todos os testes com essa abordagem resultaram em queda 
expressiva de desempenho, com redução da acurácia de validação para menos da metade do valor 
anteriormente obtido. Tais alterações possivelmente introduziram variações que descaracterizaram 
os padrões dos números nas faces dos dados, prejudicando o aprendizado.

Também foram avaliadas estratégias de tratamento de imagem, como conversão para escala de cinza, 
equalização de histograma e aplicação de \textit{thresholding}. Embora visualmente eficazes em 
destacar o contraste entre o fundo branco e o dado, esses tratamentos acabaram por remover detalhes 
importantes dos números em certos casos. A perda de informação visual comprometeu a capacidade de 
discriminação do modelo, levando à decisão de manter as imagens em sua versão RGB original, apenas 
cortadas e redimensionadas para $160 \times 160$ pixels.

Para melhorar a capacidade de aprendizado, o número de épocas foi aumentado para 40 e, posteriormente, 
50. Com isso, a acurácia de treino superou os 90\%, mas a acurácia de validação permaneceu 
significativamente inferior. Essa discrepância levantou a hipótese de um desequilíbrio na divisão dos 
conjuntos. O conjunto de validação, com apenas 10\% das amostras (proporção 90/10), continha um número 
muito limitado de imagens por classe, o que impactava negativamente a avaliação do modelo.

A divisão foi então ajustada para 80/20 (treinamento/validação), o que resultou em melhoria 
expressiva. Em uma das execuções com 50 épocas, observou-se que a acurácia de validação estabilizava 
por volta da 40ª época, formando um platô. Por isso, optou-se por reduzir o número de épocas para 40.

Além disso, o \textit{learning rate} foi ajustado para $0.0006$, com o intuito de proporcionar um 
aprendizado mais estável e menos sujeito a oscilações abruptas nos pesos da rede. Essa configuração 
final resultou em uma acurácia de treinamento de aproximadamente 84\% e acurácia de validação de 72\%, 
com perda de validação (val\_loss) estabilizada em torno de 0.95, o que indica um bom nível de generalização 
para a tarefa de classificação de oito classes distintas (valores de 1 a 8).

\subsection{Resultados e Avaliação do Modelo}

Seguindo a estrutura previamente definida, o modelo final foi treinado ao longo de 40 épocas, utilizando a arquitetura convolucional 
descrita anteriormente. O conjunto de dados, após o processamento, totalizou 1.124 imagens distribuídas em 8 classes, correspondentes 
aos valores de 1 a 8. A divisão foi realizada de forma balanceada por classe, com 80\% das imagens destinadas ao treinamento (895 amostras) 
e 20\% à validação (179 amostras), utilizando embaralhamento fixo para garantir reprodutibilidade.

A avaliação do desempenho teve como métrica principal a acurácia. A função de perda escolhida foi a \textit{Sparse Categorical Crossentropy}, 
apropriada para problemas de classificação multiclasse com rótulos inteiros. Já o otimizador utilizado foi o Adam, com taxa de aprendizado 
ajustada para 0{,}0006, visando maior estabilidade no processo de aprendizagem.

A Figura~\ref{fig:accuracy-40-epochs} apresenta a evolução da acurácia durante as 40 épocas, tanto para os dados de treinamento
quanto de validação. Observa-se uma tendência de crescimento contínuo no desempenho sobre o conjunto de treinamento, enquanto a 
validação estabiliza a partir da 30ª época — indicando que o modelo atingiu um ponto de convergência satisfatório.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figuras/Accuracy40Epochs.png}
\caption[Evolução da acurácia durante o treinamento]{
\centering
Evolução da acurácia de treinamento e validação ao longo das épocas, indicando a progressiva capacidade de generalização do modelo. \par
\textit{Fonte: Autoria própria.}}
\label{fig:accuracy-40-epochs}
\end{figure}

Complementando a análise, a Figura~\ref{fig:loss-40-epochs} mostra a redução contínua da função de perda ao longo do treinamento. 
A perda sobre o conjunto de validação se estabilizou em torno de 0{,}95, sem apresentar variações abruptas ou tendência de crescimento, 
o que reforça a ausência de sobreajuste (\textit{overfitting}) significativo.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figuras/Loss40Epochs.png}
\caption[Evolução da perda durante o treinamento]{
\centering
Evolução da perda de treinamento e validação, evidenciando um comportamento estável do modelo e ausência de sobreajuste severo. \par
\textit{Fonte: Autoria própria.}}
\label{fig:loss-40-epochs}
\end{figure}

Ao final do treinamento, o modelo alcançou acurácia de aproximadamente 84\% no conjunto de treinamento e 72\% no conjunto de validação.
Esses resultados demonstram desempenho satisfatório, considerando a variedade visual presente nas imagens — com diferentes ângulos, 
condições de iluminação e estilos de dados — e as limitações impostas pelo tamanho reduzido da base.

Para uma análise mais detalhada, foi construída a matriz de confusão (Figura~\ref{fig:confusion-matrix}), que permite observar a 
distribuição dos acertos e erros por classe. Nota-se que o modelo obteve desempenho positivo na maior parte das classes, embora erros 
mais frequentes tenham ocorrido entre os dígitos 1 e 2, e entre 6 e 7 — provavelmente devido à similaridade visual desses números sob 
determinados ângulos ou em condições adversas de iluminação.

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{figuras/confusionMatrix40Epochs.png}
\caption[Matriz de confusão do modelo]{
\centering
Matriz de confusão do modelo treinado, evidenciando os acertos e erros por classe. \par
\textit{Fonte: Autoria própria.}}
\label{fig:confusion-matrix}
\end{figure}

Além da avaliação quantitativa, uma análise qualitativa foi conduzida com o intuito de observar a robustez do modelo frente a 
variações reais nas imagens. Em geral, os resultados foram consistentes, mesmo diante de mudanças moderadas de orientação ou iluminação. 
Contudo, algumas limitações ainda persistem em casos de oclusão parcial dos números, presença de reflexos ou baixo contraste entre os 
dígitos e o fundo do dado, o que dificulta a generalização.

\subsection{Considerações Finais}

Os experimentos realizados confirmam a viabilidade da aplicação de redes neurais convolucionais no reconhecimento automático de valores 
em dados físicos de RPG. A acurácia de 72\% obtida na validação, aliada à estabilidade do treinamento e à ausência de sobreajuste crítico, 
indica que o modelo conseguiu aprender padrões relevantes mesmo com uma base limitada.

A abordagem adotada seguiu um processo iterativo e fundamentado, com diversos ajustes ao longo do desenvolvimento. Destacam-se, 
nesse contexto, a importância de uma boa divisão dos dados, da escolha adequada da arquitetura e da rejeição de estratégias que 
não apresentaram resultados satisfatórios, como certos métodos de aumento de dados e pré-processamentos agressivos.

Para trabalhos futuros, algumas possibilidades promissoras incluem:
\begin{itemize}
\item A ampliação da base de dados, com maior número de imagens por classe e inserção de situações mais variadas, como ângulos 
extremos ou iluminação irregular;
\item A experimentação com modelos mais profundos ou baseados em \textit{transfer learning}, aproveitando redes pré-treinadas;
\item A integração de reconhecimento óptico de caracteres (OCR) com segmentação automática de múltiplos dados presentes na mesma 
imagem, visando aplicações práticas em sessões reais de jogo.
\end{itemize}

Dessa forma, o presente trabalho oferece uma contribuição relevante para o uso da visão computacional em jogos físicos, 
propondo uma solução funcional e passível de expansão para o reconhecimento automatizado de valores em dados multifacetados.