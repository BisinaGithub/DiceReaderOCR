\section{Metodologia }

Este capítulo descreve os materiais e os métodos empregados no desenvolvimento do presente trabalho, 
com foco na estruturação do conjunto de dados, no processamento das imagens, no modelo de rede neural 
convolucional utilizado e nas estratégias de treinamento e validação do classificador. As decisões 
adotadas ao longo do processo são justificadas com base na realidade do projeto e nas limitaçães 
observadas durante a execução experimental.

\subsection{Coleta e Estruturação do Conjunto de Dados}
Para a realização dos testes, foi construído um conjunto de imagens próprio contendo fotografias de dados 
físicos utilizados em jogos de RPG. As imagens foram capturadas em estúdio fotográfico, com auxílio da
profissional Danielly Vitória Rodrigues, garantindo qualidade adequada de resolução, iluminação e enquadramento.

As imagens foram organizadas em pastas segundo os valores visíveis nas faces superiores dos dados, 
totalizando inicialmente 10 classes: \textit{0\_zero} até \textit{9\_nine}. Cada uma dessas pastas 
continha subpastas correspondentes aos diferentes tipos de dados (ex.: d4, d6, d8, d10)\,. 
Essa estrutura permitiu manter a diversidade de formatos dentro de cada valor, simulando 
condições reais de uso.

Entretanto, durante a análise da distribuição dos dados, foi observado que as classes 
\textit{0\_zero} até \textit{9\_nine} possuíam um número significativamente inferior de 
imagens em relação às demais. Essa escassez comprometia a representatividade estatística 
e a robustez do treinamento, além de aumentar o risco de viés ou sobreajuste da rede.

Por essa razão, optou-se por restringir o escopo do modelo inicial às classes 
\textbf{1 a 8}, que apresentavam uma quantidade razoável de imagens (acima de 80 
amostras por classe no total). As classes excluídas foram mantidas como 
possibilidade para expansão futura do projeto, mediante a ampliação da base.

\subsection{Processamento de Imagens}

Todas as imagens passaram por uma etapa de pré-processamento com o objetivo de remover 
espaços em branco ao redor dos dados e padronizar o formato das entradas. O processamento incluiu:

\begin{itemize}
\item \textbf{Corte absoluto}: Remoção de bordas fixas nas extremidades superior, inferior, 
esquerda e direita da imagem, mantendo foco no dado centralizado;
\item \textbf{Redimensionamento}: Ajuste da imagem para dimensões fixas de 160x160 pixels, 
facilitando a entrada na rede convolucional;
\item \textbf{Conversão RGB}: Padronização do canal de cor para compatibilidade com bibliotecas 
de visão computacional;
\end{itemize}

Esse tratamento foi realizado utilizando a biblioteca OpenCV. As imagens processadas foram salvas 
em pastas separadas para treino e validação.
\subsection{Divisão em Treinamento e Validação}

Para cada uma das classes (1 a 8)\,, as imagens foram embaralhadas e divididas em 80\% para 
treinamento e 20\% para validação. A divisão foi feita com semente fixa para garantir 
reprodutibilidade. Devido ao tamanho limitado do dataset, optou-se por não subdividir o 
conjunto de validação em um conjunto adicional de teste. Essa decisão visa manter uma 
quantidade mínima de imagens por classe nas avaliaçães, evitando séries com menos de cinco amostras.

Para futuros trabalhos, recomenda-se a coleta de um novo conjunto independente de imagens para 
testes finais e validação cruzada do modelo.

\subsection{Arquitetura da Rede Neural Convolucional}

A arquitetura da Rede Neural Convolucional (CNN) utilizada neste trabalho foi projetada para equilibrar 
capacidade de extração de características e simplicidade estrutural, considerando a dimensão relativamente 
pequena do conjunto de dados e o objetivo de classificação multiclasse (valores de 1 a 8). A estrutura final consiste em:

\begin{itemize}
\item Uma camada de reescalonamento (Rescaling) que normaliza os valores dos pixels das imagens de entrada para o intervalo
[0,1], dividindo por 255. Essa etapa é essencial para acelerar a convergência durante o treinamento.
\item Três blocos compostos por:
    \begin{itemize}
        \item Uma camada Conv2D com filtros 3x3, ativação \textbf{ReLU} e preenchimento 'same', com 16, 32 e 64 filtros, respectivamente; 
        \item Uma camada \textit{MaxPooling2D} após cada convolução, reduzindo as dimensões espaciais e promovendo generalização.
    \end{itemize}
\item Uma camada de \textit{Flatten}, que transforma o mapa de características extraído em um vetor unidimensional.
\item Uma camada densa \texttt{Dense}  com 128 neurônios e ativação \textbf{ReLU}, responsável por combinar as características extraídas.
\item Uma camada de saída \textit{Dense} com 8 neurônios e ativação \textbf{softmax}, adequada para classificação multiclasse com rótulos 
inteiros de 0 a 7 (associados às classes 1 a 8).
\end{itemize}

O modelo foi compilado com otimizador Adam e função de perda \textit{Sparse Categorical Crossentropy}, uma vez que os rótulos são 
inteiros e não codificados em one-hot, utilizando o otimizador Adam com taxa de aprendizado \textbf{0.0005}. A métrica de avaliação 
escolhida foi a acurácia.

A Figura~\ref{fig:modelo-cnn} apresenta um diagrama ilustrativo inspirado na arquitetura LeNet-5, 
um dos modelos de redes neurais convolucionais mais clássicos, proposto por LeCun et al. (1998) para 
reconhecimento de dígitos manuscritos. Embora a estrutura exata da rede implementada neste trabalho difira em 
termos de parâmetros, profundidade e dimensionalidade das entradas, o diagrama é representativo do fluxo de 
processamento típico de uma CNN: camadas de convolução seguidas por subamostragem (pooling), camadas densas 
totalmente conectadas e uma camada final com função de ativação \textit{softmax} para classificação multiclasse.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figuras/CNN-architecture.png}
    \caption{Esquema conceitual da arquitetura de uma CNN, inspirado na LeNet-5 \cite{lecun1998gradient}.}
    \label{fig:modelo-cnn}
\end{figure}

A Figura~\ref{fig:codigo-cnn} apresenta uma captura de tela do trecho de código-fonte responsável 
pela definição da arquitetura final da rede neural convolucional utilizada neste trabalho. 
A imagem evidencia a sequência de camadas adotadas no modelo, implementadas com a biblioteca Keras.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figuras/codigo-cnn.png}
    \caption{Trecho de código-fonte com a definição da arquitetura da CNN.}
    \label{fig:codigo-cnn}
\end{figure}

\subsection{Treinamento do Modelo}

O treinamento da rede neural convolucional (CNN) foi conduzido de forma iterativa, passando por 
diversas fases de ajuste de parâmetros, avaliação de desempenho e análise qualitativa dos resultados. 
O objetivo principal era obter um modelo capaz de classificar corretamente os valores nas faces 
superiores de dados físicos de RPG com alta acurácia e boa generalização.

Inicialmente, o modelo foi treinado por 20 épocas, com um \textit{learning rate} de $0.001$, 
sem aplicação de técnicas de \textit{data augmentation}. Essa primeira configuração foi escolhida 
por simplicidade e por estar alinhada com abordagens comuns na literatura introdutória de CNNs.
Apesar da acurácia de treino apresentar crescimento constante, a acurácia de validação mostrava 
valores baixos, sugerindo dificuldade de generalização do modelo.

Tentativas subsequentes foram feitas para aumentar a robustez do treinamento por meio de técnicas 
de aumento de dados. Utilizou-se uma camada de \textit{data augmentation} composta por rotações, 
espelhamentos e zoom aleatórios. No entanto, todos os testes com essa abordagem resultaram em queda 
expressiva de desempenho, com redução da acurácia de validação para menos da metade do valor 
anteriormente obtido. Tais alterações possivelmente introduziram variações que descaracterizaram 
os padrões dos números nas faces dos dados, prejudicando o aprendizado.

Também foram avaliadas estratégias de tratamento de imagem, como conversão para escala de cinza, 
equalização de histograma e aplicação de \textit{thresholding}. Embora visualmente eficazes em 
destacar o contraste entre o fundo branco e o dado, esses tratamentos acabaram por remover detalhes 
importantes dos números em certos casos. A perda de informação visual comprometeu a capacidade de 
discriminação do modelo, levando à decisão de manter as imagens em sua versão RGB original, apenas 
cortadas e redimensionadas para $160 \times 160$ pixels.

Para melhorar a capacidade de aprendizado, o número de épocas foi aumentado para 40 e, posteriormente, 
50. Com isso, a acurácia de treino superou os 90\%, mas a acurácia de validação permaneceu 
significativamente inferior. Essa discrepância levantou a hipótese de um desequilíbrio na divisão dos 
conjuntos. O conjunto de validação, com apenas 10\% das amostras (proporção 90/10), continha um número 
muito limitado de imagens por classe, o que impactava negativamente a avaliação do modelo.

A divisão foi então ajustada para 80/20 (treinamento/validação), o que resultou em melhoria 
expressiva. Em uma das execuções com 50 épocas, observou-se que a acurácia de validação estabilizava 
por volta da 40ª época, formando um platô. Por isso, optou-se por reduzir o número de épocas para 40.

Além disso, o \textit{learning rate} foi ajustado para $0.0005$, com o intuito de proporcionar um 
aprendizado mais estável e menos sujeito a oscilações abruptas nos pesos da rede. Essa configuração 
final resultou em uma acurácia de treinamento de aproximadamente 84\% e acurácia de validação de 72\%, 
com perda de validação (val\_loss) estabilizada em torno de 0.95, o que indica um bom nível de generalização 
para a tarefa de classificação de oito classes distintas (valores de 1 a 8).

